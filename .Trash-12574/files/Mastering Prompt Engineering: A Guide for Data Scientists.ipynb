{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256ebd09",
   "metadata": {},
   "source": [
    "# Mastering Prompt Engineering: A Guide for Data Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4914f2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9da9c",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> /generate a notebook to teach prompt engineering best practices to data scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a23dfb",
   "metadata": {},
   "source": [
    "This Jupyter notebook is designed to serve as a comprehensive guide to prompt engineering best practices for data scientists. It begins with a section on 'Understanding Prompt Engineering' where it provides a theoretical insight into prompt engineering, its significance in data science and its impact on AI model outputs. The subsequent section 'Exploring Different Types of Prompts' delves into various prompt types and their engineering for diverse use-cases, supplemented with code snippets for clarity. The 'Practical Application of Prompt Engineering' goes a step further, providing practical examples of prompt engineering in various scenarios. 'Best Practices for Prompt Engineering' provides valuable tips and tricks for creating efficient prompts, illustrated with code snippets. Lastly, the 'Challenges and Solutions in Prompt Engineering' section discusses the hurdles faced while engineering prompts and potential solutions, again supported by relevant code snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7c98e",
   "metadata": {},
   "source": [
    "## Exploring Different Types of Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda', 'James'],\n",
    "    'Age': [23, 21, 25, 22, 24],\n",
    "    'Occupation': ['Engineer', 'Doctor', 'Lawyer', 'Architect', 'Scientist']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_delete = 2\n",
    "confirmation_prompt = input(f\"Are you sure you want to delete the row: {df.iloc[row_to_delete]} ? (yes/no): \")\n",
    "if confirmation_prompt.lower() == 'yes':\n",
    "    df = df.drop(df.index[row_to_delete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_person = df.loc[df['Age'].idxmax(), 'Name']\n",
    "print(f\"The oldest person in the dataset is: {oldest_person}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcef53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_prompt = input(\"Please select a person by entering their name: \" + ', '.join(df['Name'].values) + \": \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = input(\"Please enter the new person's name, age, and occupation (comma-separated): \")\n",
    "new_person = input_prompt.split(',')\n",
    "df = df.append({'Name': new_person[0], 'Age': int(new_person[1]), 'Occupation': new_person[2]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27f544",
   "metadata": {},
   "source": [
    "## Practical Application of Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d63faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e764d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383dc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = 'This movie was fantastic! The plot was thrilling and the performances were absolutely superb.'\n",
    "new_review_count = count_vectorizer.transform([new_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baadddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(new_review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed230cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The predicted sentiment of the new review is: ', 'Positive' if prediction else 'Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99712a",
   "metadata": {},
   "source": [
    "## Best Practices for Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a82f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9905b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Translate the following English text to French and provide the translation in quotes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc353b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(prompt, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9797e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=100, \n",
    "    num_beams=5, \n",
    "    temperature=0.6,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45293613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570db965",
   "metadata": {},
   "source": [
    "## Challenges and Solutions in Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86eef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('file_path')\n",
    "text = data['text']\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, labels_train, labels_test = train_test_split(text, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c60dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(text_train)\n",
    "X_test = vectorizer.transform(text_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
