{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd74b5a",
   "metadata": {},
   "source": [
    "# An Introduction to Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823948c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba678c",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> /generate a notebook that teaches about embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1d868",
   "metadata": {},
   "source": [
    "This Jupyter notebook provides a detailed content outline on embeddings. It covers various topics such as the definition and role of embeddings in machine learning, different types of embeddings including word, image, and graph embeddings, popular algorithms for word embeddings like Word2Vec and GloVe, popular architectures for image embeddings such as CNN and ResNet, popular algorithms for graph embeddings like GraphSAGE and Node2Vec, applications of embeddings in natural language processing, computer vision, and network analysis, techniques for visualizing and interpreting embeddings, and a guide on how to train your own embeddings using different datasets and models. The aim of this notebook is to teach about embeddings and their practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ce206",
   "metadata": {},
   "source": [
    "## Types of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c67391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1715ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word embeddings\n",
    "# Word embeddings are vector representations of words in a continuous vector space.\n",
    "# They capture semantic and syntactic relationships between words.\n",
    "# Popular word embedding models include Word2Vec, GloVe, and FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919872b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for loading Word2Vec embeddings\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Word2Vec model\n",
    "word2vec_model = Word2Vec.load(\"word2vec_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de147e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image embeddings\n",
    "# Image embeddings are vector representations of images.\n",
    "# They encode visual features of images and can be used for tasks like image similarity and classification.\n",
    "# Popular image embedding models include VGG16, ResNet, and Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for loading VGG16 embeddings\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "vgg16_model = VGG16(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeaf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph embeddings\n",
    "# Graph embeddings are vector representations of nodes or subgraphs in a graph.\n",
    "# They capture structural and relational information of nodes and can be used for tasks like node classification and link prediction.\n",
    "# Popular graph embedding models include node2vec, GraphSAGE, and DeepWalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for loading node2vec embeddings\n",
    "import node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb42e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph using networkx\n",
    "graph = networkx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf624910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train node2vec model on the graph\n",
    "n2v = node2vec.Node2Vec(graph, dimensions=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node embeddings\n",
    "graph_embeddings = n2v.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1253cd8",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f082695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. They are widely used in natural language processing tasks such as sentiment analysis, machine translation, and named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular algorithms for generating word embeddings include Word2Vec and GloVe. In this section, we will explore these algorithms and their implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ff31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "# Word2Vec is a popular algorithm for learning word embeddings. It uses a neural network model to learn word representations based on their context in a given text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample sentence corpus\n",
    "corpus = [\n",
    "    ['I', 'love', 'machine', 'learning'],\n",
    "    ['machine', 'learning', 'is', 'fun'],\n",
    "    ['I', 'love', 'coding'],\n",
    "    ['coding', 'is', 'fun']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d76e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model on the corpus\n",
    "model = Word2Vec(corpus, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word vector for a specific word\n",
    "word_vector = model.wv['machine']\n",
    "print(\"Word vector for 'machine':\", word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc89de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar words to a given word\n",
    "similar_words = model.wv.most_similar('machine')\n",
    "print(\"Similar words to 'machine':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe\n",
    "# GloVe (Global Vectors for Word Representation) is another popular algorithm for generating word embeddings. It leverages global word co-occurrence statistics to learn word representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebac20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GloVe pre-trained vectors to Word2Vec format\n",
    "glove_input_file = 'glove.6B.100d.txt'  # Path to the GloVe file\n",
    "word2vec_output_file = 'glove.6B.100d.word2vec.txt'  # Path to the output file\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the converted GloVe vectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5470d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word vector for a specific word\n",
    "word_vector = glove_model['machine']\n",
    "print(\"Word vector for 'machine' (GloVe):\", word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5aad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar words to a given word\n",
    "similar_words = glove_model.most_similar('machine')\n",
    "print(\"Similar words to 'machine' (GloVe):\", similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1b063",
   "metadata": {},
   "source": [
    "## Image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08692e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_embeddings(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8302e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    embeddings = model.predict(img)\n",
    "    embeddings = np.squeeze(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a584d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72854dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'path/to/image.jpg'\n",
    "embeddings = extract_image_embeddings(image_path)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da498b43",
   "metadata": {},
   "source": [
    "## Graph embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "from stellargraph import GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a random graph\n",
    "def generate_graph():\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from([(1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 5)])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random graph\n",
    "graph = generate_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate graph embeddings using Node2Vec algorithm\n",
    "def generate_node2vec_embeddings(graph):\n",
    "    # Set Node2Vec parameters\n",
    "    p = 1.0\n",
    "    q = 1.0\n",
    "    num_walks = 10\n",
    "    walk_length = 80\n",
    "    dimensions = 128\n",
    "    window_size = 10\n",
    "    \n",
    "    # Generate random walks\n",
    "    node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q)\n",
    "    model = node2vec.fit(window=window_size, min_count=1, batch_words=4)\n",
    "    \n",
    "    # Get node embeddings\n",
    "    node_embeddings = {}\n",
    "    for node in graph.nodes():\n",
    "        node_embeddings[node] = model.wv[node]\n",
    "    \n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Node2Vec embeddings\n",
    "node2vec_embeddings = generate_node2vec_embeddings(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate graph embeddings using GraphSAGE algorithm\n",
    "def generate_graphsage_embeddings(graph):\n",
    "    # Set GraphSAGE parameters\n",
    "    dimensions = 128\n",
    "    agg_func = 'mean'\n",
    "    num_samples = [10, 5]\n",
    "    \n",
    "    # Generate GraphSAGE embeddings\n",
    "    graphsage = GraphSAGE(graph, dimensions=dimensions, agg_func=agg_func, num_samples=num_samples)\n",
    "    model = graphsage.fit()\n",
    "    \n",
    "    # Get node embeddings\n",
    "    node_embeddings = {}\n",
    "    for node in graph.nodes():\n",
    "        node_embeddings[node] = model.predict(node)\n",
    "    \n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3225ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GraphSAGE embeddings\n",
    "graphsage_embeddings = generate_graphsage_embeddings(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357930fc",
   "metadata": {},
   "source": [
    "## Applications of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_sentiment_analysis_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_embeddings = vectorizer.fit_transform(X_train)\n",
    "X_test_embeddings = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4de4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_embeddings)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e35644",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in data['text']:\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids.append(encoded_text['input_ids'])\n",
    "    attention_masks.append(encoded_text['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(data['labels'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e494d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f418d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.dropout(pooled_output)\n",
    "        output = self.linear(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a34834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(input_ids, attention_masks)\n",
    "        loss = nn.CrossEntropyLoss()(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    \n",
    "    print(\"Epoch:\", epoch+1, \"Loss:\", total_loss/total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785416b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ee8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = get_image_paths()\n",
    "image_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7925baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image_embedding = model(image)\n",
    "    image_embeddings.append(image_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = torch.cat(image_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbadd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb379bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model[-1][-1].in_features\n",
    "model[-1][-1] = nn.Linear(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9650a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    \n",
    "    print(\"Epoch:\", epoch+1, \"Loss:\", total_loss/total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.conv1 = gnn.GCNConv(num_features, 16)\n",
    "        self.conv2 = gnn.GCNConv(16, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc068df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GraphNet(num_features, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142649df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        x, edge_index, y = batch\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x, edge_index)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    \n",
    "    print(\"Epoch:\", epoch+1, \"Loss:\", total_loss/total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce4423",
   "metadata": {},
   "source": [
    "## Embedding visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733bbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4eecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.random.rand(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_embeddings = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(embedded_embeddings[:, 0], embedded_embeddings[:, 1], s=10)\n",
    "plt.title(\"Embedding Visualization\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53167f1",
   "metadata": {},
   "source": [
    "## Training your own embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60700c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eeb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embeddings(train_data, embedding_size=100, window_size=5, num_epochs=10):\n",
    "    sentences = [str(sentence).split() for sentence in train_data['text']]\n",
    "    model = Word2Vec(sentences, size=embedding_size, window=window_size, min_count=1, workers=4)\n",
    "    model.save('embeddings.bin')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = train_embeddings(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embeddings(text, embeddings_model):\n",
    "    embeddings = []\n",
    "    for word in text.split():\n",
    "        try:\n",
    "            embeddings.append(embeddings_model.wv[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba313d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['embeddings'] = train_data['text'].apply(lambda x: text_to_embeddings(x, embeddings_model))\n",
    "val_data['embeddings'] = val_data['text'].apply(lambda x: text_to_embeddings(x, embeddings_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09326d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = torch.tensor(list(train_data['embeddings']))\n",
    "val_embeddings = torch.tensor(list(val_data['embeddings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_embeddings.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_embeddings)\n",
    "val_dataset = CustomDataset(val_embeddings)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7035a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingModel(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for embeddings in train_loader:\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, torch.ones(outputs.shape))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for embeddings in val_loader:\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, torch.ones(outputs.shape))\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}: Training Loss = {running_loss/len(train_loader)}, Validation Loss = {val_loss/len(val_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
