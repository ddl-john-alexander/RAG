{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2432912d-7a0c-418a-8893-3d8418eb5a0a",
   "metadata": {},
   "source": [
    "# RAG Process - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756f04f-3c7b-4797-b7fa-7dd557bb3c88",
   "metadata": {},
   "source": [
    "This notebook shows how to use Retrieval Augmented Generation on the Domino platform to do Q&A over information that OpenAI's models have not been trained on and will not be able to provide answers out of the box. LangChain is used for both model and database access. The Process_data notebook demonstrates how to preprocess and load a document into the Pinecone vector data store to enable this process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae2000-92d6-4ffe-87c9-344680fce88a",
   "metadata": {},
   "source": [
    "### Load the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9d9425-28d8-4662-8763-1440954d6595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from getpass import getpass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946301c-fb21-493d-b1ed-a34f41f8e543",
   "metadata": {},
   "source": [
    "### Load Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575bea48-9c75-4d31-bb01-0b111d494281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#os.environ['ANTHROPIC_API_KEY'] = getpass(\"Enter Anthropic key:\")\n",
    "#os.environ['OPENAI_API_KEY'] = getpass(\"Enter OpenAI API key:\")\n",
    "#os.environ['PINECONE_API_KEY'] = getpass(\"Enter Pinecone API key:\")\n",
    "#os.environ['PINECONE_ENV'] = getpass(\"Enter Pinecone Environment:\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.getenv('PINECONE_API_ENV')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba3528-8063-4510-921e-be88fcbc1f9d",
   "metadata": {},
   "source": [
    "### Create embeddings to embed queries using OpenAI in LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be82be78-9a81-434c-9590-1984827a8196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize embedding\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "# The OpenAIEmbeddings class is instantiated with two parameters: \n",
    "# 'model' and 'openai_api_key'. 'model' is the name of the model to be used \n",
    "# and 'openai_api_key' is the key for accessing the OpenAI API.\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=model,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7b1f3-f35d-459b-9759-73acbd5ddeea",
   "metadata": {},
   "source": [
    "### Initialize Pinecone vector store with Pinecone 3.0 client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb3b605-372b-4be3-8f88-a7159f6a6740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines the field name in the data which contains the text to be embedded.\n",
    "text_field = \"text\"\n",
    "\n",
    "# Defines the name of the Pinecone index to be used.\n",
    "index_name = \"mrag-fin-docs\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)  \n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Creates an instance of the Pinecone class. It uses the previously created index,\n",
    "# the previously created embeddings object, and the text field.\n",
    "vectorstore = PineconeVectorStore(  \n",
    "    index, embeddings, text_field  \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d9f33-4ffb-4452-bb19-fdd0f2357a3e",
   "metadata": {},
   "source": [
    "### Create the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98508dd7-7c3c-4d10-bc07-5c4d92e3eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template  = \"\"\"You are an AI assistant with expertise in financial analysis. You are given the following extracted parts and a question. \n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about financial analysis, politely inform them that you are tuned to only answer questions pertaining to financial analysis.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"question\", \"context\"])\n",
    "#\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52fb96-1d85-42fa-a293-98c311b18d20",
   "metadata": {},
   "source": [
    "### Instantiate The OpenAIChat instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153856bf-65d4-40c0-b3e3-ffe7f03bbfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates an instance of the ChatOpenAI class.\n",
    "rag_llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-4',\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2655c-131f-43cb-91c3-93a3f6d14c62",
   "metadata": {},
   "source": [
    "### Instantiate the LangChain RetrievalQA chain for answering questions from the embedded data in the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8c9915-2be6-4b90-9ce7-8a2c99d7cdb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=rag_llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                       retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "                                       return_source_documents=True\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32101d91-ab88-4732-80fc-0a7a01ee873e",
   "metadata": {},
   "source": [
    "### Get question to answer in the docs and run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd823733-0c99-47b3-97d3-2afc303022c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please ask your financial analysis question: What was the gross income amount and percentage as share of total revenues in FY23\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"Please ask your financial analysis question:\")\n",
    "result = qa_chain(user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1cbcb-4ea5-4567-a47f-1eb5541582e8",
   "metadata": {},
   "source": [
    "### Retrieve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2f5476f-6fa3-48ad-99d9-8737e1608034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The gross income amount for FY23 was $169,148 million. The gross margin percentage as a share of total revenues for FY23 was 44.1%.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7332a-9837-42ee-82f1-17dc62243953",
   "metadata": {},
   "source": [
    "### Display Source Documents retrieved from the vector store and used for the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4c9507-2542-4da2-9da1-8a1ef645e8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gross Margin\\nProducts and Services gross margin and gross margin percentage for 2023, 2022 and 2021 were as follows (dollars in millions):\\n2023 2022 2021\\nGross margin:\\nProducts $ 108,803 $ 114,728 $ 105,126 \\nServices 60,345 56,054 47,710 \\nTotal gross margin $ 169,148 $ 170,782 $ 152,836 \\nGross margin percentage:\\nProducts 36.5 % 36.3 % 35.3 %\\nServices 70.8 % 71.7 % 69.7 %\\nTotal gross margin percentage 44.1 % 43.3 % 41.8 %\\nProducts Gross Margin\\nProducts gross margin decreased during 2023 compared to 2022 due to the weakness in foreign currencies relative to the U.S. dollar and lower Products\\nvolume, partially of fset by cost savings and a dif ferent Products mix.\\nProducts gross margin percentage increased during 2023 compared to 2022 due to cost savings and a different Products mix, partially offset by the weakness in\\nforeign currencies relative to the U.S. dollar and decreased leverage.\\nServices Gross Margin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents'][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7431ae-9f34-42ae-b917-8ba01260482f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
