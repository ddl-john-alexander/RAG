{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dcbf8e-bc06-45ba-a540-a467893231b8",
   "metadata": {},
   "source": [
    "# RAG Process - Inference (New version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d8fc2-c723-4acc-be51-19f87f5f80fa",
   "metadata": {},
   "source": [
    "This notebook shows how to use Retrieval Augmented Generation on the Domino platform to do Q&A over information that OpenAI's models have not been trained on and will not be able to provide answers out of the box. It also demonstrates the following enhancements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435fc7e-15c1-44bd-a40d-ecbae6888736",
   "metadata": {},
   "source": [
    "1. During the “retrieve” step, Domino’s Vector Access Layer enforces enterprise-ready credential management and security procedures, logs audit trail steps, and tracks the data’s lineage.\n",
    "1. The “augment” step involves sending the prompt and the data extracted from the Vector Database to the LLM. The data is in an embedding format that is readable by the LLM.\n",
    "1. n the “generate” step, the LLM uses the embedding to generate a response. Combined with the new Domino AI Gateway, enterprises can use prompts while ensuring data governance and reducing the likelihood of hallucinations. The workflow passes the LLM’s response back to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b50f94-e699-4c05-9fa8-c37214f3bf76",
   "metadata": {},
   "source": [
    "### Load the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9d9425-28d8-4662-8763-1440954d6595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from domino_data.vectordb import domino_pinecone3x_init_params, domino_pinecone3x_index_params\n",
    "from mlflow.deployments import get_deploy_client\n",
    "from langchain_community.embeddings import MlflowEmbeddings\n",
    "from langchain_community.chat_models import ChatMlflow\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from getpass import getpass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33cf4b-a505-4275-b8a0-0a1a230235eb",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccbb32-a0f2-4960-a091-48638fc021ad",
   "metadata": {},
   "source": [
    "Notice that the API Keys that you would normally need are commented out. Using Domino AI Gateway Endpoints for your model access and Domino Vector Data Sources for vector store access means that the API keys are managed and stored securely by the Admins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575bea48-9c75-4d31-bb01-0b111d494281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#os.environ['OPENAI_API_KEY'] = getpass(\"Enter OpenAI API key:\")\n",
    "#os.environ['PINECONE_API_KEY'] = getpass(\"Enter Pinecone API key:\")\n",
    "\n",
    "#OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "#PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.getenv('PINECONE_API_ENV')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5d043-51a4-4d83-bdd3-b0009088abff",
   "metadata": {},
   "source": [
    "### Create embeddings to embed queries using Domino AI Gateway Endpoint in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c4e74a-8525-4d86-8119-82f0d9a92254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = MlflowEmbeddings(\n",
    "    target_uri=os.environ[\"DOMINO_MLFLOW_DEPLOYMENTS\"],\n",
    "    endpoint=\"embedding-ada-002ja2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a658d-3cfc-4a8a-bda2-a9bf74318d35",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize Pinecone vector store using a Domino-specific Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb3b605-372b-4be3-8f88-a7159f6a6740",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Domino Vector Data Source name\n",
    "datasource_name = \"mrag-fin-docs-ja\"\n",
    "# Load Domino Pinecone Data Source Configuration \n",
    "pc = Pinecone(**domino_pinecone3x_init_params(datasource_name))\n",
    "\n",
    "\n",
    "# Load Pinecone Index\n",
    "index_name = \"mrag-fin-docs\"\n",
    "index = pc.Index(**domino_pinecone3x_index_params(datasource_name, index_name))\n",
    "text_field = \"text\"  # switch back to normal index for langchain\n",
    "vectorstore = PineconeVectorStore(  \n",
    "    index, embeddings, text_field   # Using embedded data from Domino AI Gateway Endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcecfb5-eed2-4c25-b526-f63e5468fd34",
   "metadata": {},
   "source": [
    "### Check index current stats as a simple checkpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6d083-5870-4fa7-98b8-a12f2905ccba",
   "metadata": {},
   "source": [
    "You'll see that the index has a ```total_vector_count```. This shows the number of vectors are currently present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8e4ced-49be-4291-8a4f-d934c0635790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 361}},\n",
       " 'total_vector_count': 361}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7af8fa-37cb-45ef-ae66-b1482e2e5c81",
   "metadata": {},
   "source": [
    "### Create the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98508dd7-7c3c-4d10-bc07-5c4d92e3eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an AI assistant with expertise in financial analysis. You are given the following extracted parts and a question. \n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about financial analysis, politely inform them that you are tuned to only answer questions pertaining to financial analysis.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"question\", \"context\"])\n",
    "#\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e0400-f14e-4148-8b58-56f4834a9c04",
   "metadata": {},
   "source": [
    "### Using the Domino AI Gateway Endpoint via Langchain ChatMLflow object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be1666-e230-453a-b59e-56ab3bdf31db",
   "metadata": {},
   "source": [
    "To use a different model, change the ```endpoint``` parameter to a different endpoint name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717c3471-7e9c-41b0-bd21-a98a470e7ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag_llm = ChatMlflow(\n",
    "        target_uri=os.environ[\"DOMINO_MLFLOW_DEPLOYMENTS\"],\n",
    "        endpoint=\"chat-gpt4-ja\", \n",
    "        temperature=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0786f1d6-24a9-4e67-a29a-f9f900d3117c",
   "metadata": {},
   "source": [
    "### Instantiate the RetrievalQA chain for answering questions from the embedded data in the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8c9915-2be6-4b90-9ce7-8a2c99d7cdb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=rag_llm, # AI Gateway Endpoint\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                       retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}), # Domino Pinecone Data Source\n",
    "                                       return_source_documents=True\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f862edf-3990-4247-a7dd-54ae805cd7d2",
   "metadata": {},
   "source": [
    "### Get question to answer in the docs and run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea7d8f4-76c5-4d45-8f83-db0215ac8b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please ask your financial analysis question: What was the gross income amount and percentage as share of total revenues in FY23\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"Please ask your financial analysis question:\")\n",
    "result = qa_chain(user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30e26a-5fae-454c-9100-7013c7624a8a",
   "metadata": {},
   "source": [
    "### Retrieve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f5476f-6fa3-48ad-99d9-8737e1608034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The gross income amount for FY23 was $169,148 million. This represented 44.1% as a share of total revenues in the same fiscal year.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4642fd-5d68-405b-8861-b39b23ffd7f2",
   "metadata": {},
   "source": [
    "### Display Source Documents retrieved from the vector store and used for the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd4c9507-2542-4da2-9da1-8a1ef645e8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gross Margin\\nProducts and Services gross margin and gross margin percentage for 2023, 2022 and 2021 were as follows (dollars in millions):\\n2023 2022 2021\\nGross margin:\\nProducts $ 108,803 $ 114,728 $ 105,126 \\nServices 60,345 56,054 47,710 \\nTotal gross margin $ 169,148 $ 170,782 $ 152,836 \\nGross margin percentage:\\nProducts 36.5 % 36.3 % 35.3 %\\nServices 70.8 % 71.7 % 69.7 %\\nTotal gross margin percentage 44.1 % 43.3 % 41.8 %\\nProducts Gross Margin\\nProducts gross margin decreased during 2023 compared to 2022 due to the weakness in foreign currencies relative to the U.S. dollar and lower Products\\nvolume, partially of fset by cost savings and a dif ferent Products mix.\\nProducts gross margin percentage increased during 2023 compared to 2022 due to cost savings and a different Products mix, partially offset by the weakness in\\nforeign currencies relative to the U.S. dollar and decreased leverage.\\nServices Gross Margin'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents'][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e0fbc-8eda-4f15-bd3a-422a590f2588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
