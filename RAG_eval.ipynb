{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8364202-a753-4e7b-9a10-f25380c86527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI, Cohere\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "#\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time,sleep\n",
    "import openai\n",
    "import tiktoken\n",
    "#\n",
    "import os\n",
    "import json\n",
    "#\n",
    "import io\n",
    "#\n",
    "import mlflow\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20365fa0-f4fb-45b0-a043-f438f8f6f5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "# get a token: https://platform.openai.com/account/api-keys\n",
    "os.environ['OPENAI_API_KEY'] = getpass(\"Enter Openai key:\")\n",
    "# get a new token: https://dashboard.cohere.ai/\n",
    "os.environ['COHERE_API_KEY'] = getpass(\"Enter Cohere key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45145ca5-a76c-4f27-840c-74a2ed52c667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path='/mnt/code/data/disease_components.csv',source_column=\"link\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6212dc5-6711-4f48-b2ff-1cc5f59b7c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionary to hold embeddings with model names as keys\n",
    "embeddings_dict = {}\n",
    "\n",
    "metadatas = []\n",
    "texts = []\n",
    "for row in data:\n",
    "  metadatas.append(row.metadata)\n",
    "  texts.append(row.page_content)\n",
    "print(len(metadatas),len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db99fb-22c0-46a4-9f5f-cc165044ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question enclosed within  3 backticks at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                         Please provide an answer which is factually correct and based on the information retrieved from the vector store.\n",
    "                         Please also mention any quotes supporting the answer if any present in the context supplied within two double quotes \"\" .\n",
    "\n",
    "                        {context}\n",
    "\n",
    "                        QUESTION:```{question}```\n",
    "                        ANSWER:\n",
    "                      \"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n",
    "#\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7022b-abd2-4fc9-9e20-484ead4582fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load model based on name\n",
    "def get_qa_chain(llm_name='OpenAI', embedding_model_name='OpenAI'):\n",
    "    \n",
    "    qa = None\n",
    "    doc_store = embeddings_dict.get(embedding_model_name)\n",
    "    \n",
    "    if llm_name == 'Cohere':\n",
    "        rag_llm = Cohere(model=\"command\",\n",
    "                         temperature=0,\n",
    "                         cohere_api_key=os.environ[\"COHERE_API_KEY\"])\n",
    "    else:\n",
    "        rag_llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k',\n",
    "                             openai_api_key=os.environ[\"COHERE_API_KEY\"],\n",
    "                             temperature=0)\n",
    "            \n",
    "        return RetrievalQA.from_chain_type(llm=rag_llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                  retriever=doc_store.as_retriever(search_kwargs={\"k\": 5}),\n",
    "                                  return_source_documents=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfa402-8090-4967-b17f-6c0cd07157ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(embedding_model_name='HuggingFace'):\n",
    "    \n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    \n",
    "    if embedding_model_name == 'OpenAI':\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "           \n",
    "    elif embedding_model_name =='BGE':\n",
    "        embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en\",\n",
    "                                      model_kwargs=model_kwargs,\n",
    "                                      encode_kwargs=encode_kwargs\n",
    "                                     )\n",
    "    else:\n",
    "         embeddings = HuggingFaceEmbeddings(model_kwargs = model_kwargs,\n",
    "                                            encode_kwargs = encode_kwargs,\n",
    "                                           )\n",
    "        \n",
    "    store = Qdrant.from_texts(texts,\n",
    "                                  metadatas=metadatas,\n",
    "                                  embedding=embeddings,\n",
    "                                   path=\"/mnt/data/local_qdrant\",,\n",
    "                                  prefer_grpc=True,\n",
    "                                  collection=f\"{embedding_model_name}_medical_qa_search\")\n",
    "    \n",
    "    embeddings_dict[embedding_model_name] = store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9cd44-61ad-478d-86d9-6a7c7b6bb109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your search params\n",
    "llms = ('OpenAI', 'Cohere')  # Model names\n",
    "embedding_models = ('HuggingFace', 'OpenAI', 'BGE')  # Embedding names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebaa89-fb97-4010-8fc0-0833b6df1953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "for model_name in embedding_models:\n",
    "    compute_embedding(model_name, texts, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403ee56-1330-4328-b8c5-4f9d680c375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the evaluation dataset\n",
    "#In order to evaluate the qa system we generated a few relevant questions and answers\n",
    "eval_questions = [\n",
    "    \"I have persistent back pain since 4 weeks,I workouut but havent had any sports injury.What might be the cause of the back pain?\",\n",
    "    \"I have shortness of breath and frequently feel nauseated and tired.What can be the possible cause?\",\n",
    "    \"My 12 year old son has Poor coordination Unsteady walk and a tendency to stumble while walking and poor coordination between two hands.What might be the possible cuase?\",\n",
    "    \"What is Baby acne ?\",\n",
    "    \"What is Botulism ?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"From the symptoms mentioned you might have a disloacted disk\",  # incorrect answer\n",
    "    \"You might have asthama.\",  # incorrect answer\n",
    "    \" Movement and coordination problems associated with cerebral palsy.Please consult a doctor for better diagnosis.\",\n",
    "    \"Baby acne is small, inflamed bumps on a baby's face, neck, back or chest.\",\n",
    "    \"Botulism is a rare and potentially fatal illness caused by a toxin produced by the bacterium Clostridium botulinum.\",\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truths\": [eval_answers[i]]}\n",
    "    for i, q in enumerate(eval_questions)\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b74ed-6ab8-4c08-8f2b-89f1ec13ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the evaluation chains\n",
    "from ragas.langchain.evalchain import RagasEvaluatorChain\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain = RagasEvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain = RagasEvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain = RagasEvaluatorChain(metric=context_relevancy)\n",
    "context_recall_chain = RagasEvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1b6de-581d-4f42-887b-0886cbf60657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all combinations of these parameters\n",
    "search_space = list(itertools.product(llms, embedding_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015a710-0cbb-4b7a-95ac-e46fec4054b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_name, embedding_name):\n",
    "    \n",
    "    qa_chain = get_qa_chain(model_name, embedding_name)\n",
    "    \n",
    "    predictions = qa.batch(examples)\n",
    "    faithfulness_scores = faithfulness_chain.evaluate(examples, predictions)\n",
    "    context_recall_scores = context_recall_chain.evaluate(examples, predictions)\n",
    "    answer_rel_scores = answer_rel_chain.evaluate(examples, predictions)\n",
    "    context_rel_scores = context_rel_chain.evaluate(examples, predictions)\n",
    "    \n",
    "    # Combine scores into a dataframe\n",
    "    df_scores = pd.DataFrame({\n",
    "        'faithfulness': faithfulness_scores,\n",
    "        'context_recall': context_recall_scores,\n",
    "        'answer_relevance': answer_rel_scores,\n",
    "        'context_relevance': context_rel_scores\n",
    "    })\n",
    "    \n",
    "    # Calculate the median of each column\n",
    "    median_scores = df_scores.median().to_dict()\n",
    "    \n",
    "    # Return the results of the experiment \n",
    "    return median_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c9fcf-72fe-48f5-bfd1-fa0ab46b14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and set the experiment name\n",
    "experiment_name = \"RAG_Parameter_search\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Iterate through each combination and execute the MLflow runs\n",
    "for llm_name, embedding_model_name in search:\n",
    "    run_name = f\"{llm_name}_{embedding_model_name}_run\"\n",
    "    print(f'run_name={run_name}')\n",
    "    # Log parameters\n",
    "    print(f\"model : {llm_name}\")\n",
    "    print(f\"embedding : {embedding_model_name}\")\n",
    "   # Run the experiment\n",
    "    results = run_experiment(llm_name, embedding_model_name)\n",
    "    # Log results\n",
    "    for key, value in results.items():\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab4561-efc0-4fb1-8d18-9dc95fe140d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and set the experiment name\n",
    "# experiment_name = \"RAG_Parameter_search\"\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# # Iterate through each combination and execute the MLflow runs\n",
    "# for llm_name, embedding_model_name in search:\n",
    "#     run_name = f\"{llm_name}_{embedding_model_name}_run\"\n",
    "#     with mlflow.start_run(run_name=run_name):\n",
    "#         # Log parameters\n",
    "#         mlflow.log_param(\"model\", llm_name)\n",
    "#         mlflow.log_param(\"embedding\", embedding_model_name)\n",
    "\n",
    "#         # Run the experiment\n",
    "#         results = run_experiment(llm_name, embedding_model_name)\n",
    "\n",
    "#         # Log results\n",
    "#         for key, value in results.items():\n",
    "#             mlflow.log_metric(key, value)\n",
    "\n",
    "#         # End the run\n",
    "#         mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
